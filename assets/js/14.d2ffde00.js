(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{387:function(a,s,t){"use strict";t.r(s);var e=t(46),n=Object(e.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"datanode"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#datanode"}},[a._v("#")]),a._v(" DataNode")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210902093056464-16305462634723.png",alt:"image-20210902093056464"}})]),a._v(" "),t("h2",{attrs:{id:"数据完整性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#数据完整性"}},[a._v("#")]),a._v(" 数据完整性")]),a._v(" "),t("p",[a._v("奇偶校验位 如果传输数据1为偶数个数则为0  如果为奇数个1则为1")]),a._v(" "),t("p",[a._v("如果原始数据与接收数据发生改变又恰好奇偶性一致 则这个现象我们称为校验碰撞")]),a._v(" "),t("p",[a._v("crc校验位  32位")]),a._v(" "),t("p",[a._v("md5 128位")]),a._v(" "),t("p",[a._v("sha1 160位")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210902094110493.png",alt:"image-20210902094110493"}})]),a._v(" "),t("h2",{attrs:{id:"扩展集群"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩展集群"}},[a._v("#")]),a._v(" 扩展集群")]),a._v(" "),t("p",[a._v("服役新数据节点")]),a._v(" "),t("ol",[t("li",[t("p",[a._v("克隆 修改主机名 ip")])]),a._v(" "),t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#复制module文件夹 在其他集群中复制  和环境变量")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sudo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("rsync")]),a._v(" -av /opt/module hadoop105:/opt\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sudo")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("rsync")]),a._v(" -av /etc/profile.d hadoop105:/etc\n")])])])]),a._v(" "),t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#在扩展机中删除logs data 文件夹")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /opt/module/hadoop-3.1.3/\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("rm")]),a._v(" -rf data logs\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" /etc/profile\nhadoop version\n")])])])]),a._v(" "),t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("hdfs --daemon start datanode \n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v(" --daemon start nodemanager  \njps\n")])])])])]),a._v(" "),t("p",[a._v("此方式是手动启动 如果想要群启动则需要配置免密登陆")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#在102中配置")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" /opt/module/hadoop-3.1.3/etc/hadoop/workers \n")])])]),t("p",[a._v("追加上地址")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("hadoop105\n")])])]),t("p",[a._v("同步所有集群")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("xsync /opt/module/hadoop-3.1.3/etc/hadoop/workers \n")])])]),t("h3",{attrs:{id:"添加黑-白名单"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#添加黑-白名单"}},[a._v("#")]),a._v(" 添加黑/白名单")]),a._v(" "),t("p",[a._v("在hadoop文件夹下 新建balcklist和whitelist")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#主机上写 102")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /opt/module/hadoop-3.1.3/etc/hadoop\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("touch")]),a._v(" balcklist\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("touch")]),a._v(" whitelist\n")])])]),t("p",[a._v("添加白名单  一般whitelist内容和workers相同")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" whitelist\n")])])]),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("hadoop102\nhadoop103\nhadoop104\nhadoop105\n")])])]),t("p",[a._v("再编辑hdfs-size.xml")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" hdfs-site.xml \n")])])]),t("p",[a._v("添加以下内容")]),a._v(" "),t("div",{staticClass:"language-xml extra-class"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.hosts.exclude"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("/opt/module/hadoop-3.1.3/etc/hadoop/balcklist"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.hosts"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("/opt/module/hadoop-3.1.3/etc/hadoop/whitelist"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n")])])]),t("p",[a._v("重启集群")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("stop-dfs.sh\n")])])]),t("p",[a._v("开启")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("start-dfs.sh\n")])])]),t("h3",{attrs:{id:"黑名单退役"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#黑名单退役"}},[a._v("#")]),a._v(" 黑名单退役")]),a._v(" "),t("p",[a._v("编辑 balcklist 添加黑名单地址")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" balcklist\nhdfs dfsadmin -refreshNodes  "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#刷新节点")]),a._v("\n")])])]),t("p",[a._v("退役的机器 自动上传文件到服役中的其他主机中")]),a._v(" "),t("p",[a._v("关闭节点")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("hdfs --daemon stop datanode\n")])])]),t("h2",{attrs:{id:"datenode-多目录配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#datenode-多目录配置"}},[a._v("#")]),a._v(" DateNode 多目录配置")]),a._v(" "),t("p",[a._v("DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" hdfs-site.xml\n")])])]),t("p",[a._v("多个目录之间逗号隔开")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("dfs.datanode.data.dir"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("file:///"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("${hadoop.tmp.dir}")]),a._v("/dfs/data1,file:///"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("${hadoop.tmp.dir}")]),a._v("/dfs/data"),t("span",{pre:!0,attrs:{class:"token operator"}},[t("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("2")]),a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),t("p",[a._v("配置完成后重启")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("hdfs --daemon stop datanode\nhdfs --daemon start datanode\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);