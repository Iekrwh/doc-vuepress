(window.webpackJsonp=window.webpackJsonp||[]).push([[135],{509:function(t,s,a){"use strict";a.r(s);var n=a(46),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"beautifulsoup4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup4"}},[t._v("#")]),t._v(" Beautifulsoup4")]),t._v(" "),a("p",[a("a",{attrs:{href:"http://www.crummy.com/software/BeautifulSoup/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Beautiful Soup"),a("OutboundLink")],1),t._v(" 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.")]),t._v(" "),a("p",[t._v("Beautifulsoup 四种解析器")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("解析器")]),t._v(" "),a("th",[t._v("使用方法")]),t._v(" "),a("th",[t._v("优势")]),t._v(" "),a("th",[t._v("劣势")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("Python标准库")]),t._v(" "),a("td",[a("code",[t._v('BeautifulSoup(markup, "html.parser")')])]),t._v(" "),a("td",[t._v("Python的内置标准库执行速度适中文档容错能力强")]),t._v(" "),a("td",[t._v("Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差")])]),t._v(" "),a("tr",[a("td",[t._v("lxml HTML 解析器")]),t._v(" "),a("td",[a("code",[t._v('BeautifulSoup(markup, "lxml")')])]),t._v(" "),a("td",[t._v("速度快文档容错能力强")]),t._v(" "),a("td",[t._v("需要安装C语言库")])]),t._v(" "),a("tr",[a("td",[t._v("lxml XML 解析器")]),t._v(" "),a("td",[a("code",[t._v('BeautifulSoup(markup, ["lxml-xml"])``BeautifulSoup(markup, "xml")')])]),t._v(" "),a("td",[t._v("速度快唯一支持XML的解析器")]),t._v(" "),a("td",[t._v("需要安装C语言库")])]),t._v(" "),a("tr",[a("td",[t._v("html5lib")]),t._v(" "),a("td",[a("code",[t._v('BeautifulSoup(markup, "html5lib")')])]),t._v(" "),a("td",[t._v("最好的容错性以浏览器的方式解析文档生成HTML5格式的文档")]),t._v(" "),a("td",[t._v("速度慢不依赖外部扩展")])])])]),t._v(" "),a("h2",{attrs:{id:"构造方法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#构造方法"}},[t._v("#")]),t._v(" 构造方法")]),t._v(" "),a("ul",[a("li",[t._v('BeautifulSoup(html,"html.parser")')])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://wsjkw.sc.gov.cn/scwsjkw/gzbd/fyzt.shtml"')]),t._v("\nres"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encoding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utf-8"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#转为utf-u解码")]),t._v("\nhtml"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将源码转为文本赋值给html")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'html.parser'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#对象化html     "lxml"')]),t._v("\n")])])]),a("h2",{attrs:{id:"四大对象种类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四大对象种类"}},[t._v("#")]),t._v(" "),a("strong",[t._v("四大对象种类")])]),t._v(" "),a("ol",[a("li",[t._v("Tag   HTML中的一个个标签\n"),a("ol",[a("li",[t._v("Name（标签名） 通过 .name获取")]),t._v(" "),a("li",[t._v('Attributes（属性）   字典获取  tag["class"]  tag.attrs   可以获取整个字典')]),t._v(" "),a("li",[t._v("Multi-valued attributes（多值属性）  也是字典获取 返回一个列表")])])]),t._v(" "),a("li",[t._v("NavigableString  获取标签内部的文字用 .string 即可")]),t._v(" "),a("li",[t._v("BeautifulSoup   表示的是一个文档的内容")]),t._v(" "),a("li",[t._v("Comment  是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号。")])]),t._v(" "),a("h2",{attrs:{id:"遍历文档树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#遍历文档树"}},[t._v("#")]),t._v(" 遍历文档树")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html_doc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'html.parser'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("ul",[a("li",[a("p",[t._v("soup.tag  使用标签名进行遍历  soup.head   soup.h2")])]),t._v(" "),a("li",[a("p",[t._v("Tag.contents   获取该标签中所有元素")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("head_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head\nhead_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <head><title>The Dormouse's story</title></head>")]),t._v("\n\nhead_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contents\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("The Dormouse's story"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ntitle_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" head_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntitle_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <title>The Dormouse's story</title>")]),t._v("\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("Tag.children  对tag的子节点进行循环")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" title_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("Tag.descendants  可以对所有tag的子孙节点进行递归循环")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" head_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("descendants"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("soup.strings  获取tag中的字符串包含子标签")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" string "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("repr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# u"The Dormouse\'s story"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'\\n\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# u"The Dormouse\'s story"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'\\n\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Once upon a time there were three little sisters; and their names were\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Elsie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u',\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Lacie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u' and\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Tillie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u';\\nand they lived at the bottom of a well.'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'\\n\\n'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'...'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'\\n'")]),t._v("\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("soup.stripped_strings  输出的字符串中可能包含了很多空格或空行,使用 "),a("code",[t._v(".stripped_strings")]),t._v(" 可以去除多余空白内容:")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" string "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripped_strings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("repr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# u"The Dormouse\'s story"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# u"The Dormouse\'s story"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Once upon a time there were three little sisters; and their names were'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Elsie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u','")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Lacie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'and'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'Tillie'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u';\\nand they lived at the bottom of a well.'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u'...'")]),t._v("\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("Tag.parent  获取某个元素的父节点")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("title_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title\ntitle_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <title>The Dormouse's story</title>")]),t._v("\ntitle_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <head><title>The Dormouse's story</title></head>")]),t._v("\n")])])])])])]),t._v(" "),a("li",[a("p",[t._v("Tag.parents  可以递归得到元素的所有父辈节点")]),t._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("link "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\nlink\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" parent "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" link"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" parent "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# p")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# body")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# html")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [document]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# None")]),t._v("\n")])])])])])])]),t._v(" "),a("h2",{attrs:{id:"搜索文档树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#搜索文档树"}},[t._v("#")]),t._v(" 搜索文档树")]),t._v(" "),a("ul",[a("li",[t._v("soud.find()    搜索第一个符合条件的标签")]),t._v(" "),a("li",[t._v("soud.find_all( name , attrs , recursive , string , **kwargs )   搜索所有符合条件的标签")])]),t._v(" "),a("p",[t._v("唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.")]),t._v(" "),a("h3",{attrs:{id:"字符串"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#字符串"}},[t._v("#")]),t._v(" 字符串")]),t._v(" "),a("p",[t._v("最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [<b>The Dormouse's story</b>]")]),t._v("\n")])])]),a("h3",{attrs:{id:"正则表达式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#正则表达式"}},[t._v("#")]),t._v(" 正则表达式")]),t._v(" "),a("p",[t._v("如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 "),a("code",[t._v("match()")]),t._v(" 来匹配内容.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" tag "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# body")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# b")]),t._v("\n")])])]),a("h3",{attrs:{id:"列表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#列表"}},[t._v("#")]),t._v(" 列表")]),t._v(" "),a("p",[t._v("如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [<b>The Dormouse's story</b>,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]')]),t._v("\n")])])]),a("h3",{attrs:{id:"keyword-属性值"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#keyword-属性值"}},[t._v("#")]),t._v(" keyword   属性值")]),t._v(" "),a("p",[t._v("如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'link2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#搜索所有id为link2的标签")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]')]),t._v("\n")])])]),a("h3",{attrs:{id:"按css搜索"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#按css搜索"}},[t._v("#")]),t._v(" 按CSS搜索")]),t._v(" "),a("p",[t._v("class 在Python中是保留字,使用 class 做参数会导致语法错误.从Beautiful Soup的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的tag")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sister"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]')]),t._v("\n")])])]),a("p",[t._v("class 属性是 多值属性 .按照CSS类名搜索tag时,可以分别搜索tag中的每个CSS类名")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("css_soup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<p class=\"body strikeout\"></p>'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncss_soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"p"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"strikeout"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<p class="body strikeout"></p>]')]),t._v("\n\ncss_soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"p"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"body"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<p class="body strikeout"></p>]')]),t._v("\n")])])]),a("p",[t._v("搜索 class 属性时也可以通过CSS值完全匹配")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("css_soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"p"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"body strikeout"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<p class="body strikeout"></p>]')]),t._v("\n")])])]),a("p",[t._v("完全匹配 class 的值时,如果CSS类名的顺序与实际不符,将搜索不到结果")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" attrs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"class"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sister"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]')]),t._v("\n")])])]),a("h3",{attrs:{id:"string-参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#string-参数"}},[t._v("#")]),t._v(" String 参数")]),t._v(" "),a("p",[t._v("通过 string 参数可以搜搜文档中的字符串内容")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Elsie"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [u'Elsie']")]),t._v("\n\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Tillie"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Elsie"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Lacie"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [u'Elsie', u'Lacie', u'Tillie']")]),t._v("\n\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Dormouse"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('u"The Dormouse\'s story"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('u"The Dormouse\'s story"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("is_the_only_string_within_a_tag")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("Return "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" this string "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" the only child of its parent tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("string"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("is_the_only_string_within_a_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [u\"The Dormouse's story\", u\"The Dormouse's story\", u'Elsie', u'Lacie', u'Tillie', u'...']")]),t._v("\n")])])]),a("h3",{attrs:{id:"limit-参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limit-参数"}},[t._v("#")]),t._v(" limit 参数")]),t._v(" "),a("p",[t._v("find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" limit"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]')]),t._v("\n")])])]),a("h3",{attrs:{id:"recursive-参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#recursive-参数"}},[t._v("#")]),t._v(" recursive 参数")]),t._v(" "),a("p",[t._v("调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False")]),t._v(" "),a("h3",{attrs:{id:"父辈节点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#父辈节点"}},[t._v("#")]),t._v(" 父辈节点")]),t._v(" "),a("p",[t._v("find_all() 和 find() 只搜索当前节点的所有子节点,孙子节点等. find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同,搜索文档搜索文档包含的内容")]),t._v(" "),a("ul",[a("li",[t._v("soud.find_parents()")]),t._v(" "),a("li",[t._v("soud.find_parents()")])]),t._v(" "),a("h2",{attrs:{id:"修改文档树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#修改文档树"}},[t._v("#")]),t._v(" 修改文档树")]),t._v(" "),a("p",[t._v("Beautiful Soup的强项是文档树的搜索,但同时也可以方便的修改文档树")]),t._v(" "),a("h3",{attrs:{id:"修改tag的名称和属性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#修改tag的名称和属性"}},[t._v("#")]),t._v(" 修改tag的名称和属性")]),t._v(" "),a("p",[t._v("重命名一个tag,改变属性的值,添加或删除属性")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<b class=\"boldest\">Extremely bold</b>'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b\n\ntag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blockquote"')]),t._v("\ntag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'class'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'verybold'")]),t._v("\ntag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\ntag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <blockquote class="verybold" id="1">Extremely bold</blockquote>')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("del")]),t._v(" tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'class'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("del")]),t._v(" tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <blockquote>Extremely bold</blockquote>")]),t._v("\n")])])]),a("h3",{attrs:{id:"修改-string"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#修改-string"}},[t._v("#")]),t._v(" 修改 .string")]),t._v(" "),a("p",[t._v("给tag的 .string 属性赋值,就相当于用当前的内容替代了原来的内容")]),t._v(" "),a("p",[t._v("如果当前的tag包含了其它tag,那么给它的 .string 属性赋值会"),a("strong",[t._v("覆盖掉原有的所有内容包括子tag")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("markup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\ntag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"New link text."')]),t._v("\ntag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="http://example.com/">New link text.</a>')]),t._v("\n")])])]),a("h3",{attrs:{id:"append"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#append"}},[t._v("#")]),t._v(" append()")]),t._v(" "),a("p",[t._v("Tag.append() 方法想tag中添加内容")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("soup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"<a>Foo</a>"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Bar"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsoup\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <html><head></head><body><a>FooBar</a></body></html>")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contents\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [u'Foo', u'Bar']")]),t._v("\n")])])]),a("h3",{attrs:{id:"clear"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#clear"}},[t._v("#")]),t._v(" clear()")]),t._v(" "),a("p",[t._v("Tag.clear() 方法移除当前tag的内容")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("markup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\n\ntag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clear"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="http://example.com/"></a>')]),t._v("\n")])])]),a("h3",{attrs:{id:"extract"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#extract"}},[t._v("#")]),t._v(" extract()")]),t._v(" "),a("p",[t._v("PageElement.extract() 方法将当前tag移除文档树,并作为方法结果返回")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("markup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\n\ni_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\na_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="http://example.com/">I linked to</a>')]),t._v("\n\ni_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <i>example.com</i>")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n")])])]),a("h3",{attrs:{id:"decompose"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#decompose"}},[t._v("#")]),t._v(" decompose()")]),t._v(" "),a("p",[t._v("Tag.decompose() 方法将当前节点移除文档树并完全销毁")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("markup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\n\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decompose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\na_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="http://example.com/">I linked to</a>')]),t._v("\n")])])]),a("h3",{attrs:{id:"replace-with"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#replace-with"}},[t._v("#")]),t._v(" replace_with()")]),t._v(" "),a("p",[t._v("PageElement.replace_with() 方法移除文档树中的某段内容,并用新tag或文本节点替代它:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("markup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("markup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a\n\nnew_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("new_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnew_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"example.net"')]),t._v("\na_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace_with"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\na_tag\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="http://example.com/">I linked to <b>example.net</b></a>')]),t._v("\n")])])]),a("h2",{attrs:{id:"bs4的简单使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bs4的简单使用"}},[t._v("#")]),t._v(" bs4的简单使用")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\nurl"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://wsjkw.sc.gov.cn/scwsjkw/gzbd/fyzt.shtml"')]),t._v("\nres"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encoding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utf-8"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#转为utf-u解码")]),t._v("\nhtml"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将源码转为文本赋值给html")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'html.parser'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#对象化html     "lxml"')]),t._v("\nh "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'h2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#寻找文本中 h2标签的内容")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nh "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'h2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#只获取h2标签中的内容")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\na "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#会寻找文本中第一个a标签")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\na "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attrs   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#获取a标签中  href以及 target  存放在字典中")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);