(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{388:function(s,a,t){"use strict";t.r(a);var e=t(46),l=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs"}},[s._v("#")]),s._v(" HDFS")]),s._v(" "),t("p",[s._v("HDFS(Hadoop Distributed File System)  它是一个文件系统 用于存储文件 通过目录树来定位文件   其次它是分布式的")]),s._v(" "),t("p",[s._v("HDFS的使用场景: 适合一次写入 多次读出的场景 且不支持文件的修改")]),s._v(" "),t("p",[s._v("优点:")]),s._v(" "),t("ol",[t("li",[s._v("高容错性  自动保存多个副本 某一个副本丢失 可以自动恢复")]),s._v(" "),t("li",[s._v("适合处理大数据")]),s._v(" "),t("li",[s._v("可构建在廉价机器上 通过多副本机制 提高可靠性")])]),s._v(" "),t("p",[s._v("缺点:")]),s._v(" "),t("ol",[t("li",[s._v("不适合低延时时数据访问 比如毫秒级的数据")]),s._v(" "),t("li",[s._v("无法高效的对大量小文件进行存储")]),s._v(" "),t("li",[s._v("不支持并发写入 文件随机修改  仅支持数据的append 追加")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210906151144956.png",alt:"image-20210906151144956"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210906151224638.png",alt:"image-20210906151224638"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/Iekrwh/md-images/raw/master/images/image-20210906151300031.png",alt:"image-20210906151300031"}})]),s._v(" "),t("h2",{attrs:{id:"命令行操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#命令行操作"}},[s._v("#")]),s._v(" 命令行操作")]),s._v(" "),t("p",[s._v("以 hadoop fs  或者 hdfs dfs  为关键字")]),s._v(" "),t("h3",{attrs:{id:"hdfs-到-hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-到-hdfs"}},[s._v("#")]),s._v(" HDFS 到 HDFS")]),s._v(" "),t("p",[s._v("大部分linux命令都支持  需要在hadoop fs -拼接命令")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("cp   如:hadoop fs -cp 1.txt 2.txt")])]),s._v(" "),t("li",[t("p",[s._v("mv")])]),s._v(" "),t("li",[t("p",[s._v("chown")])]),s._v(" "),t("li",[t("p",[s._v("chmod")])]),s._v(" "),t("li",[t("p",[s._v("mkdir")])]),s._v(" "),t("li",[t("p",[s._v("du  统计文件夹的大小信息")])]),s._v(" "),t("li",[t("p",[s._v("df")])]),s._v(" "),t("li",[t("p",[s._v("cat")])]),s._v(" "),t("li",[t("p",[s._v("rm")])]),s._v(" "),t("li",[t("p",[s._v("setrep  设置HDFS中文件的副本数据  默认为节点(集群)数 并且不可以超节点数最大为节点数")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("hadoop fs -setrep "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" /1.txt\n")])])])])])])]),s._v(" "),t("h3",{attrs:{id:"本地-到-hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地-到-hdfs"}},[s._v("#")]),s._v(" 本地 到 HDFS")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("put  上传")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -put 文件 HDFS内文件路径")]),s._v("\nhadoop fs -put "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(".txt /\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("copyFromLocal  从本地复制到HDFS  支持多线程")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -copyFromLocal 文件 HDFS内文件路径")]),s._v("\nhadoop fs -copyFromLocal  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(".txt /\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("moveFromLocal  从本地复制到HDFS")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -moveFromLocal  文件 HDFS内文件路径")]),s._v("\nhadoop fs -moveFromLocal   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(".txt /\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("appendToFile  将指定文件内容或者指定内容追加到HDFS文件末尾")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -appendToFile  文件 HDFS内文件路径  如要指定内容则文件名忽略填写 - 既可")]),s._v("\nhadoop fs -appendToFile   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(".txt /1.txt\n")])])])])])])]),s._v(" "),t("h3",{attrs:{id:"hdfs-到-本地"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-到-本地"}},[s._v("#")]),s._v(" HDFS 到 本地")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("get  从HDFS下载到本地")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -get  HDFS内文件  本地文件路径")]),s._v("\nhadoop fs -get   /2.txt /\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("copyToLocal   与get一致")])]),s._v(" "),t("li",[t("p",[s._v("getmerge  合并下载")]),s._v(" "),t("ul",[t("li",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#hadoop fs -get  HDFS内多个文件  本地文件")]),s._v("\nhadoop fs -get   /*.txt /1.txt\n")])])])])])])])])}),[],!1,null,null,null);a.default=l.exports}}]);